import ssl
ssl._create_default_https_context = ssl._create_unverified_context

import torch
import clip
import os
import random
import json
import asyncio
import requests
import ollama
import edge_tts
import re
import glob
import config
import subprocess
import shutil
import traceback
import proglog
from moviepy.editor import *
from moviepy.audio.AudioClip import AudioArrayClip
import numpy as np
from openai import OpenAI
from vfx_core import VisualEffects

# å¼ºåˆ¶ MoviePy ä½¿ç”¨å†…ç½® FFmpeg
if os.path.exists(config.FFMPEG_BINARY):
    os.environ["IMAGEIO_FFMPEG_EXE"] = config.FFMPEG_BINARY

# ä¿®å¤ PIL
import PIL.Image
if not hasattr(PIL.Image, 'ANTIALIAS'):
    PIL.Image.ANTIALIAS = PIL.Image.LANCZOS

# --- çº¿ç¨‹å®‰å…¨çš„ WebSocket Logger ---
class WebSocketLogger(proglog.ProgressBarLogger):
    def __init__(self, log_callback, loop):
        super().__init__(init_state=None, bars=None, ignored_bars=None, logged_bars='all', min_time_interval=0, ignore_bars_under=0)
        self.log_callback = log_callback
        self.loop = loop
    
    def callback(self, **changes):
        for (item, state) in changes.items():
            if not isinstance(state, dict): continue
            total = state.get('total')
            index = state.get('index')
            if total and index:
                percent = int((index / total) * 100)
                if percent % 5 == 0: 
                    msg = f"â³ æ¸²æŸ“è¿›åº¦: {percent}%"
                    asyncio.run_coroutine_threadsafe(self.log_callback(msg), self.loop)

    def message(self, message):
        asyncio.run_coroutine_threadsafe(self.log_callback(f"[MoviePy] {message}"), self.loop)


class VideoEngine:
    def __init__(self):
        self.ASSETS_DIR = config.ASSETS_DIR
        self.TEMP_DIR = config.TEMP_DIR
        self.FONT_PATH = config.FONT_PATH
        self.runtime_pexels_key = ""
        self.runtime_pixabay_key = ""
        
        self.llm_provider = config.LLM_PROVIDER
        self.llm_api_key = config.API_KEY
        self.llm_base_url = config.API_BASE_URL
        if self.llm_provider == 'api':
            self.llm_model_name = config.API_MODEL_NAME
        else:
            self.llm_model_name = config.OLLAMA_MODEL
        
        for d in ["video", "sfx", "music", "fonts", "outputs"]: 
            os.makedirs(os.path.join(self.ASSETS_DIR, d), exist_ok=True)
        os.makedirs(self.TEMP_DIR, exist_ok=True)
        os.makedirs(config.OUTPUT_DIR, exist_ok=True)

        # === [æ–°å¢] å‘é‡æ•°æ®åº“åˆå§‹åŒ– ===
        self.vector_index_path = os.path.join(config.ASSETS_DIR, "vector_index.pt") # å‡è®¾ä½ çš„ç´¢å¼•åœ¨è¿™é‡Œ
        self.clip_model_path = "ViT-B-32.pt" # ä½ çš„æœ¬åœ°æ¨¡å‹è·¯å¾„
        self.device = "mps" if torch.backends.mps.is_available() else "cpu"
        self.clip_model = None
        self.clip_preprocess = None
        self.vector_db = None
        
    def _load_vector_resources(self):
        """æ‡’åŠ è½½ï¼šåªæœ‰ç”¨åˆ°å‘é‡æœç´¢æ—¶æ‰åŠ è½½ï¼ŒèŠ‚çœå†…å­˜"""
        if self.clip_model is None:
            print(f"ğŸ§  Loading CLIP model...")
            if os.path.exists(self.clip_model_path):
                self.clip_model, self.clip_preprocess = clip.load(self.clip_model_path, device=self.device)
            else:
                self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
            
        if self.vector_db is None:
            if os.path.exists(self.vector_index_path):
                print(f"ğŸ“‚ Loading Vector Index...")
                self.vector_db = torch.load(self.vector_index_path)
                # é¢„åŠ è½½å‘é‡åˆ°æ˜¾å­˜/å†…å­˜åŠ é€Ÿè®¡ç®—
                if len(self.vector_db) > 0:
                    self.db_vectors = torch.cat([item['vector'] for item in self.vector_db]).to(self.device)
            else:
                print("âš ï¸ Vector index not found.")
                self.vector_db = []

    async def generate_tts_audio(self, text, voice, output_path, engine="edge", sovits_url=None):
        """
        ç»Ÿä¸€çš„è¯­éŸ³ç”Ÿæˆæ¥å£
        engine: 'edge' | 'sovits'
        """
        # 1. GPT-SoVITS é€»è¾‘
        if engine == "sovits" and sovits_url:
            try:
                # è¿™é‡Œå‡è®¾ SoVITS å…¼å®¹æ ‡å‡† API æ ¼å¼ï¼Œæ ¹æ®ä½ å®é™…éƒ¨ç½²çš„æƒ…å†µè°ƒæ•´
                payload = {
                    "text": text,
                    "text_language": "zh"
                }
                # æ³¨æ„ï¼šrequests æ˜¯åŒæ­¥çš„ï¼Œå»ºè®®ç”¨ aiohttpï¼Œè¿™é‡Œä¸ºäº†ç®€å•æ¼”ç¤ºç”¨ requests
                # å®é™…ç”Ÿäº§ä¸­æœ€å¥½æ”¾å…¥çº¿ç¨‹æ± 
                def _run_request():
                    return requests.post(f"{sovits_url}/tts", json=payload, timeout=10)
                
                resp = await asyncio.to_thread(_run_request)
                
                if resp.status_code == 200:
                    with open(output_path, "wb") as f:
                        f.write(resp.content)
                    return True
            except Exception as e:
                print(f"âŒ SoVITS Error: {e}, falling back to Edge-TTS")
        
        # 2. Edge-TTS é€»è¾‘ (é»˜è®¤)
        try:
            communicate = edge_tts.Communicate(text, voice)
            await communicate.save(output_path)
            return True
        except Exception as e:
            print(f"âŒ Edge-TTS Error: {e}")
            return False
    # --- ä»å‘é‡åº“éšæœºè·å–ä¸€ä¸ªæ²¡ç”¨è¿‡çš„è§†é¢‘ ---
    def _get_random_vector_clip(self, exclude_set):
        """
        å…œåº•é€»è¾‘ï¼šå½“æœç´¢ä¸åˆ°ç´ æï¼Œæˆ–è€…ç´ æä¸å¤Ÿå¡«æ»¡æ—¶é—´æ—¶ï¼Œ
        ä»åº“é‡Œéšæœºæä¸€ä¸ªæ²¡ç”¨è¿‡çš„è§†é¢‘ã€‚
        """
        self._load_vector_resources()
        if not self.vector_db: return None
        
        # å°è¯• 50 æ¬¡å¯»æ‰¾æœªä½¿ç”¨çš„
        for _ in range(50):
            item = random.choice(self.vector_db)
            path = item['path']
            if os.path.exists(path) and path not in exclude_set:
                return path
        
        # å¦‚æœå®åœ¨æ‰¾ä¸åˆ°ï¼ˆåº“å¤ªå°ï¼‰ï¼Œåªèƒ½å‹‰å¼ºå¤ç”¨ä¸€ä¸ª
        item = random.choice(self.vector_db)
        return item['path'] if os.path.exists(item['path']) else None

    def search_vector_match(self, query, top_k=5, exclude_set=None):
        """
        è¿”å› Top K ä¸ªç»“æœï¼Œä¸”ä¸åœ¨ exclude_set ä¸­
        """
        self._load_vector_resources()
        if not self.vector_db or self.db_vectors is None: return []
        if exclude_set is None: exclude_set = set()

        with torch.no_grad():
            text_input = clip.tokenize([query]).to(self.device)
            text_features = self.clip_model.encode_text(text_input)
            text_features /= text_features.norm(dim=-1, keepdim=True)
            
            similarity = (100.0 * text_features @ self.db_vectors.T).softmax(dim=-1)
            values, indices = similarity[0].topk(min(top_k * 2, len(self.vector_db))) # å¤šå–ä¸€ç‚¹æ–¹ä¾¿è¿‡æ»¤
            
        results = []
        for i in range(len(indices)):
            idx = indices[i].item()
            item = self.vector_db[idx]
            path = item['path']
            
            # æ ¸å¿ƒï¼šè¿‡æ»¤æ‰ä¸å­˜åœ¨çš„æ–‡ä»¶ å’Œ å…¨å±€å·²ä½¿ç”¨çš„æ–‡ä»¶
            if os.path.exists(path) and path not in exclude_set:
                results.append(path)
                if len(results) >= top_k: break
                
        return results

    def get_video_clip_smart(self, video_info, duration, use_vector=True, use_pexels=True):
        """
        æ™ºèƒ½è·å–è§†é¢‘ç´ æï¼š
        1. æœ¬åœ°æ–‡ä»¶åç²¾ç¡®åŒ¹é…
        2. å‘é‡æ•°æ®åº“æ¨¡ç³ŠåŒ¹é… (æ–°å¢)
        3. Pexels åœ¨çº¿æœç´¢
        4. å…œåº•é€»è¾‘
        """
        # è§£æ video_info (å…¼å®¹å‰ç«¯ä¼ æ¥çš„å„ç§æ ¼å¼)
        search_query = ""
        if isinstance(video_info, dict):
            if video_info.get('type') == 'local' and os.path.exists(video_info.get('src', '')):
                return VideoFileClip(video_info['src']) # ç»å¯¹è·¯å¾„ç›´æ¥è¿”å›
            search_query = video_info.get('tags', '') or video_info.get('name', '')
        elif isinstance(video_info, str):
            search_query = video_info

        # A. å‘é‡æœç´¢ (å¦‚æœå¼€å¯)
        if use_vector and search_query:
            matches = self.search_vector_match(search_query)
            if matches:
                # ç­–ç•¥ï¼šå¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œä¸”æ—¶é•¿ä¸å¤Ÿï¼Œè¿™é‡Œå¯ä»¥åšå¤šé•œå¤´æ‹¼æ¥ (å‚è€ƒä¹‹å‰çš„é€»è¾‘)
                # è¿™é‡Œç®€å•å¤„ç†ï¼šéšæœºé€‰ä¸€ä¸ªåŒ¹é…åº¦é«˜çš„
                best_match = matches[0]
                print(f"âœ… Vector Match: {search_query} -> {os.path.basename(best_match)}")
                return self._process_clip(best_match, duration)

        # B. Pexels åœ¨çº¿æœç´¢ (å¦‚æœå¼€å¯)
        if use_pexels and search_query:
            # å¤ç”¨ä½ åŸæœ‰çš„ download_video é€»è¾‘ï¼Œè¿™é‡Œç®€åŒ–æ¼”ç¤º
            # pexels_file = self.download_video(search_query) 
            # if pexels_file: ...
            pass 

        # C. å…œåº• (éšæœºæœ¬åœ°)
        # ... (ä¿ç•™ä½ åŸæœ‰çš„å…œåº•é€»è¾‘) ...
        return ColorClip(size=(1920, 1080), color=(0,0,0), duration=duration)

    def get_dynamic_visuals_smart(self, candidate_paths, target_duration, global_used_set, effect_config=None):
        """
        effect_config: JSONä¸­çš„ visual_effect å­—æ®µ
        """
        clips = []
        current_duration = 0.0
        candidate_queue = list(candidate_paths)
        
        # é»˜è®¤ç‰¹æ•ˆé…ç½®
        if not effect_config: 
            effect_config = {"camera": "Zoom_In_Slow", "filter": "None"}

        while current_duration < target_duration:
            selected_path = None
            
            # A. ä¼˜å…ˆä»å€™é€‰æ± æ‹¿
            if candidate_queue:
                selected_path = candidate_queue.pop(0)
                if selected_path in global_used_set: selected_path = None
            
            # B. éšæœºå…œåº•
            if not selected_path:
                selected_path = self._get_random_vector_clip(global_used_set)
                if not selected_path: break

            try:
                global_used_set.add(selected_path)
                
                # 1. åŠ è½½åŸºç¡€è§†é¢‘
                clip = VideoFileClip(selected_path).without_audio()
                
                # 2. ã€ç»å¯¹é™æ€ã€‘çš„å°ºå¯¸é¢„å¤„ç† (Reset to 1080p)
                # è¿™ä¸€æ­¥ä¿è¯è¿›å…¥ VFX ä¹‹å‰ï¼Œè§†é¢‘æ˜¯æ ‡å‡†çš„ 1920x1080 æ•´æ•°å°ºå¯¸
                target_h = 1080
                target_w = 1920
                
                if clip.h != target_h: 
                    clip = clip.resize(height=target_h)
                
                if clip.w > target_w:
                    # é™æ€å±…ä¸­è£å‰ª
                    x_c = clip.w // 2
                    half_w = target_w // 2
                    clip = clip.crop(x1=x_c - half_w, width=target_w, height=target_h)
                elif clip.w < target_w:
                    clip = clip.resize(width=target_w)
                    y_c = clip.h // 2
                    half_h = target_h // 2
                    clip = clip.crop(y1=y_c - half_h, width=target_w, height=target_h)
                
                # -----------------------------------------------------------
                # 3. [åº”ç”¨ Plan B ç‰¹æ•ˆ] 
                # è°ƒç”¨æ–°çš„ vfx_core (OpenCVç‰ˆ)
                
                from vfx_core import VisualEffects
                
                camera_move = effect_config.get("camera", "Zoom_In_Slow")
                filter_type = effect_config.get("filter", "None")
                
                # å…ˆæ»¤é•œ
                clip = VisualEffects.apply_filter(clip, filter_type)
                # åè¿é•œ (ç°åœ¨æ˜¯åƒç´ çº§å¤„ç†ï¼Œä¸æ¶‰åŠå…ƒæ•°æ®ï¼Œç»å¯¹å®‰å…¨)
                clip = VisualEffects.apply_camera_movement(clip, camera_move)
                # -----------------------------------------------------------
                
                clips.append(clip)
                current_duration += clip.duration
                
            except Exception as e:
                print(f"âš ï¸ Clip Error {selected_path}: {e}")
                continue

        # å…œåº•ï¼šå¦‚æœæ²¡ç”Ÿæˆä»»ä½•ç‰‡æ®µ
        if not clips:
            print("âš ï¸ No clips valid, returning black screen.")
            return ColorClip(size=(1920, 1080), color=(0,0,0), duration=target_duration)

        # 4. æ‹¼æ¥
        # method="compose" æ¯” "chain" æ›´ç¨³å¥ï¼Œèƒ½å¤„ç†ä¸åŒå±æ€§çš„è§†é¢‘
        final_clip = concatenate_videoclips(clips, method="compose")
        
        # 5. æ—¶é—´ä¿®å‰ª
        if final_clip.duration >= target_duration:
            final_clip = final_clip.subclip(0, target_duration)
        else:
            final_clip = final_clip.loop(duration=target_duration)
            
        return final_clip

    def _process_clip(self, path, duration):
        """ç»Ÿä¸€çš„ç´ æå¤„ç†ï¼šé™éŸ³ã€å¾ªç¯ã€è£å‰ª"""
        try:
            vc = VideoFileClip(path).without_audio()
            if vc.duration < duration:
                vc = vc.loop(duration=duration)
            else:
                vc = vc.subclip(0, duration)
            return vc.resize(height=1080).crop(x1=vc.w/2-960, width=1920, height=1080)
        except:
            return ColorClip(size=(1920, 1080), color=(0,0,0), duration=duration)

    def parse_direct_json(self, json_data):
        scenes = []
        timeline = json_data.get('timeline', [])
        
        print("ğŸ” Pre-scanning vector database for frontend preview...")
        
        for block in timeline:
            # æå–å…³é”®è¯
            visual_tags = block.get('visual_search_queries', [])
            # æå–ç‰¹æ•ˆé…ç½®
            visual_effect = block.get('visual_effect', {})
            
            # æå–éŸ³æ•ˆå (ç”¨äºåç»­æŸ¥æ‰¾)
            sfx_name = block.get('center_highlight', {}).get('sfx', '')

            # === [æ–°å¢] é¢„æœç´¢è§†é¢‘ ===
            # è¿™é‡Œåªæœ Top 1ï¼Œç”¨äºç»™å‰ç«¯å±•ç¤ºâ€œç”±äºä½¿ç”¨äº†è¿™ä¸ªå…³é”®è¯ï¼ŒåŒ¹é…åˆ°äº†è¿™ä¸ªè§†é¢‘â€
            # å®é™…æ¸²æŸ“æ—¶ä¼šæœ Top 5 è¿›è¡Œå¡«å……ï¼Œè¿™é‡Œåªæ˜¯é¢„è§ˆ
            preview_video = "random"
            if visual_tags:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå…³é”®è¯å»æœ
                matches = self.search_vector_match(visual_tags[0], top_k=1)
                if matches:
                    # è¿”å›ç»™å‰ç«¯ç»å¯¹è·¯å¾„ï¼Œæˆ–è€…åŸºäº server.py çš„ç›¸å¯¹ URL
                    # å‡è®¾å‰ç«¯èƒ½é€šè¿‡æ–‡ä»¶åè®®æˆ–é™æ€æœåŠ¡è®¿é—®
                    preview_video = matches[0] 

            scene = {
                "text": block['sentence_text'],
                "visual_tags": visual_tags, 
                "video": preview_video, # å‰ç«¯æ‹¿åˆ°è¿™ä¸ªå­—æ®µå°±å¯ä»¥æ˜¾ç¤ºäº†
                
                # å°†ç‰¹æ•ˆé…ç½®ä¼ é€’ä¸‹å»
                "visual_effect": visual_effect,
                
                "keywords": block.get('center_highlight', {}).get('text', ''),
                "is_emphasis": block.get('center_highlight', {}).get('enabled', False),
                "sfx": sfx_name,
                
                "voice": config.DEFAULT_VOICE,
                "audio_padding": 0.2
            }
            scenes.append(scene)
            
        return scenes

    def _get_random_vector_clip(self, exclude_set):
        """
        å…œåº•é€»è¾‘ï¼šå½“æœç´¢ä¸åˆ°ç´ æï¼Œæˆ–è€…ç´ æä¸å¤Ÿå¡«æ»¡æ—¶é—´æ—¶ï¼Œ
        ä»åº“é‡Œéšæœºæä¸€ä¸ªæ²¡ç”¨è¿‡çš„è§†é¢‘ã€‚
        """
        self._load_vector_resources()
        if not self.vector_db: return None
        
        # å°è¯• 50 æ¬¡å¯»æ‰¾æœªä½¿ç”¨çš„
        for _ in range(50):
            item = random.choice(self.vector_db)
            path = item['path']
            if os.path.exists(path) and path not in exclude_set:
                return path
        
        # å¦‚æœå®åœ¨æ‰¾ä¸åˆ°ï¼ˆåº“å¤ªå°ï¼‰ï¼Œåªèƒ½å‹‰å¼ºå¤ç”¨ä¸€ä¸ª
        item = random.choice(self.vector_db)
        return item['path'] if os.path.exists(item['path']) else None


    def set_api_keys(self, pexels, pixabay):
        self.runtime_pexels_key = pexels.strip()
        self.runtime_pixabay_key = pixabay.strip()

    def set_llm_config(self, provider, api_key, base_url, model_name):
        self.llm_provider = provider
        if provider == 'api':
            if api_key: self.llm_api_key = api_key
            if base_url: self.llm_base_url = base_url
            if model_name: self.llm_model_name = model_name
        else:
            if model_name: self.llm_model_name = model_name

    def _get_key(self, key_type):
        if key_type == "pexels":
            return self.runtime_pexels_key if self.runtime_pexels_key else config.PEXELS_API_KEY
        elif key_type == "pixabay":
            return self.runtime_pixabay_key if self.runtime_pixabay_key else config.PIXABAY_API_KEY
        return ""

    def sanitize_filename(self, name):
        name = str(name).replace(" ", "_")
        return re.sub(r'[^\w\-_]', '', name)

    def check_ollama_status(self):
        try:
            resp = requests.get("http://127.0.0.1:11434/", timeout=2)
            if resp.status_code == 200: return True
        except: return False
        return False

    def _call_llm(self, prompt):
        print(f"ğŸ¤– Calling LLM ({self.llm_provider}): {self.llm_model_name}...")
        if self.llm_provider == 'api':
            if not self.llm_api_key: raise Exception("API Key æœªé…ç½®")
            client = OpenAI(api_key=self.llm_api_key, base_url=self.llm_base_url)
            try:
                response = client.chat.completions.create(
                    model=self.llm_model_name,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7, stream=False
                )
                return response.choices[0].message.content
            except Exception as e:
                print(f"âŒ API Error: {e}"); raise e
        else:
            if not self.check_ollama_status(): raise ConnectionError("Ollama æœåŠ¡æœªè¿æ¥")
            try:
                response = ollama.chat(model=self.llm_model_name, messages=[{'role':'user','content':prompt}])
                return response['message']['content']
            except Exception as e:
                print(f"âŒ Ollama Error: {e}"); raise e

    def split_text_by_breath(self, text):
        # é»˜è®¤æœ€å¤§å®½åº¦ 18 ä¸ªå­— (è¶…è¿‡å°±å°è¯•åœ¨é€—å·å¤„åˆ‡å¼€ï¼Œå¦‚æœæ²¡é€—å·ï¼Œä¹Ÿä¼šä¿ç•™å®Œæ•´å¥å­)
        return self.smart_split_text(text, max_chars=30)

    # --- [æ ¸å¿ƒä¼˜åŒ–] æ™ºèƒ½è´ªå©ªåˆå¹¶åˆ†æ®µç®—æ³• ---
    def smart_split_text(self, text, max_chars=30):
        """
        ä¼˜åŒ–ç‰ˆï¼šå¢åŠ å¯¹ç ´æŠ˜å·çš„æ”¯æŒï¼Œç§»é™¤æš´åŠ›åˆ‡åˆ†ï¼Œæ”¹ç”¨è½¯æˆªæ–­ã€‚
        """
        text = text.replace("\n", " ").strip()
        text = text.strip('"').strip("'").strip('â€œ').strip('â€').strip('(').strip(')').strip('ï¼ˆ').strip('ï¼‰')
        if not text: return []
        
        text = text.replace("...", "@@ELLIPSIS@@")
        
        # 1. è¡¥å……æ”¯æŒç ´æŠ˜å· â€”â€” å’Œç©ºæ ¼ä½œä¸ºåˆ‡åˆ†ç‚¹
        atoms = re.split(r'([ï¼Œã€‚ï¼?ï¼Ÿ,!.ã€;ï¼›ï¼š:â€”â€”\s]+)', text)
        
        segments = []
        current_segment = ""
        for item in atoms:
            if not item: continue
            current_segment += item
            if re.search(r'[ï¼Œã€‚ï¼?ï¼Ÿ,!.ã€;ï¼›ï¼š:â€”â€”\s]+', item):
                segments.append(current_segment)
                current_segment = ""
        if current_segment: segments.append(current_segment)
        
        final_chunks = []
        current_buffer = ""
        
        for seg in segments:
            seg = seg.replace("@@ELLIPSIS@@", "...")
            is_strong_end = bool(re.search(r'[ã€‚ï¼ï¼Ÿ!?]', seg))
            
            # 2. åªæœ‰å½“ buffer ç¡®å®å¤ªé•¿ï¼Œä¸”æ–°ç‰‡æ®µåŠ ä¸Šå»ä¼šæ˜¾è‘—è¿‡é•¿æ—¶æ‰åˆ‡åˆ†
            # å¦‚æœå½“å‰ buffer å­—æ•°å¾ˆå°‘ï¼ˆä¾‹å¦‚<5ï¼‰ï¼Œå³ä½¿åŠ ä¸Šå»è¶…æ ‡äº†ä¹Ÿå°½é‡ä¸åˆ‡ï¼Œé˜²æ­¢å­¤å„¿è¯
            if len(current_buffer) + len(seg) > max_chars:
                if len(current_buffer) > 5: 
                    final_chunks.append(current_buffer.strip())
                    current_buffer = ""
            
            current_buffer += seg
            
            if is_strong_end:
                final_chunks.append(current_buffer.strip())
                current_buffer = ""
                
        if current_buffer.strip():
            final_chunks.append(current_buffer.strip())
            
        # 3. å½»åº•åˆ é™¤åŸæœ‰çš„ Step 4 (æš´åŠ›å¯¹åŠåˆ‡)ï¼Œé˜²æ­¢â€œé™·é˜±â€è¢«åˆ‡æˆâ€œé™·â€â€œé˜±â€
        # æ”¹ä¸ºæœ€åä¸€é“è¿‡æ»¤
        return [c for c in final_chunks if re.search(r'[\u4e00-\u9fa5a-zA-Z0-9]', c)]

    def hex_to_ass_color(self, hex_color):
        hex_color = str(hex_color).lstrip('#')
        if len(hex_color) == 6:
            r, g, b = hex_color[:2], hex_color[2:4], hex_color[4:]
            return f"&H00{b}{g}{r}".upper()
        return "&H00FFFFFF"

    def apply_ass_highlight(self, text, keywords_str, highlight_color_ass, normal_color_ass):
        if not keywords_str: return text
        keywords = [k.strip() for k in re.split(r'[,ï¼Œ]', keywords_str) if k.strip()]
        keywords.sort(key=len, reverse=True)
        final_text = text
        for k in keywords:
            if k in final_text:
                ass_code = f"{{\\c{highlight_color_ass}}}{k}{{\\c{normal_color_ass}}}"
                final_text = final_text.replace(k, ass_code)
        return final_text

    def generate_ass_header(self, style_config):
        norm = style_config.get('normal', {})
        emp = style_config.get('emphasis', {})
        n_size = norm.get('size', 100)
        n_color = self.hex_to_ass_color(norm.get('color', '#FFFFFF'))
        n_outline = self.hex_to_ass_color(norm.get('outline', '#000000'))
        e_size = emp.get('size', 180)
        e_color = self.hex_to_ass_color(emp.get('color', '#FF0000'))
        e_outline = self.hex_to_ass_color(emp.get('outline', '#FFFFFF'))

        header = f"""[Script Info]
        Title: Auto Video
        ScriptType: v4.00+
        WrapStyle: 0
        ScaledBorderAndShadow: yes
        YCbCr Matrix: TV.601
        PlayResX: 1920
        PlayResY: 1080

        [V4+ Styles]
        Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
        Style: Normal,Arial,{n_size},{n_color},{n_color},{n_outline},&H80000000,1,0,0,0,100,100,0,0,1,4,0,2,30,30,450,1
        Style: Emphasis,Arial,{e_size},{e_color},{e_color},{e_outline},&H00000000,1,0,0,0,100,100,0,0,1,6,0,5,30,30,350,1
        Style: Yellow,Arial,{e_size},{e_color},{e_color},{e_outline},&H00000000,1,0,0,0,100,100,0,0,1,5,0,5,30,30,350,1

        [Events]
        Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
        """
        return header

    def format_ass_time(self, seconds):
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        cs = int((seconds % 1) * 100)
        return f"{h}:{m:02d}:{s:02d}.{cs:02d}"

    def clean_for_subtitle(self, text):
        return re.sub(r'[ï¼Œã€‚ï¼?ï¼Ÿ,!.ã€;ï¼›ï¼š:\"\'â€œâ€\[\]ã€ã€‘]+', ' ', text).strip()

    async def run_ffmpeg_async(self, cmd, log_callback, loop):
        if cmd[0] == "ffmpeg":
            if os.path.exists(config.FFMPEG_BINARY):
                cmd[0] = config.FFMPEG_BINARY
        
        def run_sync():
            process = subprocess.Popen(
                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
                universal_newlines=True, encoding='utf-8', errors='ignore'
            )
            buffer = ""
            while True:
                char = process.stderr.read(1)
                if not char and process.poll() is not None: break
                if char:
                    buffer += char
                    if char in ['\n', '\r']:
                        line = buffer.strip()
                        if line:
                            if "frame=" in line or "time=" in line:
                                asyncio.run_coroutine_threadsafe(log_callback(f"[FFmpeg] {line}"), loop)
                            elif "Error" in line:
                                asyncio.run_coroutine_threadsafe(log_callback(f"âš ï¸ {line}"), loop)
                        buffer = ""
            return process.returncode

        return await asyncio.to_thread(run_sync)

    # --- èµ„æºåŠŸèƒ½ (ä¿æŒä¸å˜) ---
    def search_local_videos(self, tag):
        video_dir = os.path.join(self.ASSETS_DIR, "video")
        if not os.path.exists(video_dir): return []
        files = [f for f in os.listdir(video_dir) if f.endswith(('.mp4', '.mov'))]
        matches = [f for f in files if tag.lower() in f.lower()]
        return matches if matches else files

    def download_video(self, query):
        key = self._get_key("pexels")
        if not key or "ç²˜è´´" in key: return None
        headers = {"Authorization": key, "User-Agent": "Mozilla/5.0"}
        url = f"https://api.pexels.com/videos/search?query={query}&per_page=1&orientation=landscape"
        try:
            r = requests.get(url, headers=headers, timeout=15)
            data = r.json()
            if not data.get('videos'): return None
            vid = data['videos'][0]
            tags = vid.get('tags', [])
            tag_slug = self.sanitize_filename(query)
            extra = "_".join([self.sanitize_filename(t)[:10] for t in tags[:5]])
            fname = f"pexels_{vid['id']}_{tag_slug}_{extra}.mp4"
            if len(fname) > 200: fname = fname[:200] + ".mp4"
            vfiles = vid['video_files']
            target = next((vf['link'] for vf in video_files if vf['width']==1920), vfiles[0]['link'])
            c = requests.get(target, timeout=60).content
            path = os.path.join(self.ASSETS_DIR, "video", fname)
            with open(path, 'wb') as f: f.write(c)
            return fname
        except: return None

    def download_video_by_url(self, download_url, video_id, tags):
        try:
            tag_slug = self.sanitize_filename(tags)[:50]
            fname = f"pexels_{video_id}_{tag_slug}.mp4"
            path = os.path.join(self.ASSETS_DIR, "video", fname)
            if os.path.exists(path): return fname
            headers = {"User-Agent": "Mozilla/5.0"}
            c = requests.get(download_url, headers=headers, timeout=120).content
            with open(path, 'wb') as f: f.write(c)
            return fname
        except: return None

    def search_online_videos(self, query):
        key = self._get_key("pexels")
        if not key or "ç²˜è´´" in key: return {"error": "API Key Missing"}
        headers = {"Authorization": key, "User-Agent": "Mozilla/5.0"}
        url = f"https://api.pexels.com/videos/search?query={query}&per_page=12&orientation=landscape"
        try:
            r = requests.get(url, headers=headers, timeout=15)
            data = r.json()
            results = []
            for v in data.get('videos', []):
                preview = v['video_files'][0]['link']
                for f in v['video_files']:
                    if 600 <= f.get('width', 0) <= 1280: preview = f['link']; break
                download = v['video_files'][0]['link']
                for f in v['video_files']:
                    if f.get('width', 0) == 1920: download = f['link']; break
                tags_str = query
                if v.get('tags'): tags_str = v['tags'][0]
                results.append({
                    "type": "online", "id": v['id'], "src": preview,
                    "download_url": download, "tags": tags_str, "name": f"Pexels ID: {v['id']}"
                })
            return results
        except Exception as e: return {"error": str(e)}

    # --- éŸ³æ•ˆæœç´¢ (MyInstants) ---
    def search_online_sfx(self, query):
        url = "https://www.myinstants.com/api/v1/instants/"
        params = {"name": query, "format": "json"}
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            r = requests.get(url, params=params, headers=headers, timeout=5)
            data = r.json()
            results = []
            for item in data.get('results', [])[:15]:
                sound = item.get('sound')
                if not sound: continue
                name = item.get('name', 'SFX').replace("'", "").replace('"', '')
                results.append({
                    "id": str(random.randint(10000, 99999)),
                    "name": name, "duration": 2, "download_url": sound, "preview_url": sound
                })
            return results
        except: return {"error": "SFX Error"}

    # --- éŸ³æ•ˆæŸ¥æ‰¾ï¼šæ”¯æŒæ¨¡ç³ŠåŒ¹é… ---
    def _find_local_sfx(self, keyword):
        """
        åœ¨ assets/sfx ç›®å½•ä¸‹æ¨¡ç³ŠæŸ¥æ‰¾åŒ…å« keyword çš„æ–‡ä»¶
        ä¾‹å¦‚ keyword="Boom", å¯ä»¥åŒ¹é…åˆ° "Impact_Boom_01.mp3"
        """
        if not keyword: return None
        sfx_dir = os.path.join(self.ASSETS_DIR, "sfx")
        if not os.path.exists(sfx_dir): return None
        
        # è·å–æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        files = [f for f in os.listdir(sfx_dir) if f.lower().endswith(('.mp3', '.wav', '.aac', '.m4a'))]
        
        keyword = keyword.lower().strip()
        
        # 1. ä¼˜å…ˆï¼šæ–‡ä»¶åä»¥ keyword å¼€å¤´ (ä¾‹å¦‚ "Boom_01.mp3")
        for f in files:
            if f.lower().startswith(keyword):
                return os.path.join(sfx_dir, f)

        # 2. æ¬¡é€‰ï¼šæ–‡ä»¶ååŒ…å« keyword (ä¾‹å¦‚ "Cinematic_Boom.mp3")
        for f in files:
            if keyword in f.lower():
                return os.path.join(sfx_dir, f)
        
        return None

    def download_sfx_manual(self, query, download_url=None):
        # 1. å…ˆå°è¯•æœ¬åœ°æ¨¡ç³Šæœç´¢
        local_path = self._find_local_sfx(query)
        if local_path:
            print(f"   ğŸ”Š Local SFX Found: '{query}' -> {os.path.basename(local_path)}")
            return os.path.basename(local_path) # è¿”å›æ–‡ä»¶åå³å¯ï¼Œåç»­é€»è¾‘ä¼šå¤„ç†è·¯å¾„

        # 2. å¦‚æœæ²¡æ‰¾åˆ°ä¸”æœ‰ URLï¼Œå°è¯•ä¸‹è½½ (ä¿ç•™åŸæœ‰é€»è¾‘)
        if download_url:
            return self.get_dynamic_sfx(query, os.path.join(self.ASSETS_DIR, "sfx"), download_url=download_url)
            
        # 3. éƒ½æ²¡æœ‰ï¼Œå°è¯•å»åœ¨çº¿åº“åŒ¹é… (MyInstantsç­‰ï¼Œä¿ç•™åŸæœ‰é€»è¾‘)
        return self.get_dynamic_sfx(query, os.path.join(self.ASSETS_DIR, "sfx"))

    def get_dynamic_sfx(self, search_term, save_dir, download_url=None):
        if not search_term: return None
        local = [f for f in os.listdir(save_dir) if not f.startswith('.')]
        for f in local:
            if search_term.lower() in f.lower(): return os.path.join(save_dir, f)
        
        fallback = {
            "whoosh": "https://assets.mixkit.co/active_storage/sfx/2568/2568-preview.mp3",
            "ding": "https://assets.mixkit.co/active_storage/sfx/961/961-preview.mp3",
            "boom": "https://assets.mixkit.co/active_storage/sfx/3004/3004-preview.mp3",
            "keyboard": "https://assets.mixkit.co/active_storage/sfx/238/238-preview.mp3"
        }
        dl = None
        for k,v in fallback.items():
            if k in search_term.lower(): dl=v; break
        if dl:
            try:
                c = requests.get(dl, headers={'User-Agent':'Mozilla/5.0'}).content
                p = os.path.join(save_dir, f"auto_{self.sanitize_filename(search_term)}.mp3")
                with open(p, 'wb') as f: f.write(c)
                return p
            except: pass

        if download_url:
            try:
                base = f"auto_{self.sanitize_filename(search_term)}.mp3"
                path = os.path.join(save_dir, base)
                if not os.path.exists(path):
                    c = requests.get(download_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=15).content
                    with open(path, 'wb') as f: f.write(c)
                return base
            except: pass
            
        return None

    def load_sfx_resource(self, sfx_query, sfx_dir):
        if not sfx_query: return None
        exact = os.path.join(sfx_dir, sfx_query)
        if os.path.exists(exact): return exact
        local = [f for f in os.listdir(sfx_dir) if not f.startswith('.')]
        for f in local:
            if sfx_query.lower() in f.lower(): return os.path.join(sfx_dir, f)
        return None

    def get_video_clip_safe(self, video_info, duration, log_callback=None):
        video_path = None
        if isinstance(video_info, str):
            v_type = "random" if video_info == "random" else "local"
            v_name = video_info
            v_dl_url = ""
            v_tags = ""
            v_id = ""
        else:
            v_type = video_info.get('type', 'local')
            v_name = video_info.get('name', '')
            v_dl_url = video_info.get('download_url', '')
            v_tags = video_info.get('tags', '')
            v_id = video_info.get('id', 'temp')

        if v_type == 'online':
            safe_tag = self.sanitize_filename(v_tags)
            fname = f"pexels_{v_id}_{safe_tag}.mp4"
            local_path = os.path.join(self.ASSETS_DIR, "video", fname)
            if os.path.exists(local_path):
                video_path = local_path
            else:
                try:
                    c = requests.get(v_dl_url, timeout=60).content
                    with open(local_path, 'wb') as f: f.write(c)
                    video_path = local_path
                except: video_path = None
        elif v_type == 'local':
            if v_name and v_name != 'random':
                p = os.path.join(self.ASSETS_DIR, "video", v_name)
                if os.path.exists(p): video_path = p

        if not video_path:
            v_dir = os.path.join(self.ASSETS_DIR, "video")
            v_files = [f for f in os.listdir(v_dir) if f.endswith('.mp4')]
            if v_files: video_path = os.path.join(v_dir, random.choice(v_files))

        if not video_path:
            return ColorClip(size=(1920, 1080), color=(0,0,0), duration=duration)

        try:
            vc = VideoFileClip(video_path)
            # å‹æš—
            vc = vc.fx(vfx.colorx, 0.7)
            vc = vc.without_audio()

            if vc.duration < duration:
                vc = vc.loop(duration=duration)
            else:
                max_s = max(0, vc.duration - duration - 0.1)
                s = random.uniform(0, max_s)
                vc = vc.subclip(s, s+duration)
            
            vc = vc.set_duration(duration)
            vc = vc.resize(height=1080)
            if vc.w > 1920: vc = vc.crop(x1=vc.w/2-960, width=1920, height=1080)
            elif vc.w < 1920: vc = vc.resize(width=1920).crop(x1=0, y1=vc.h/2-540, width=1920, height=1080)
            return vc
        except:
            return ColorClip(size=(1920, 1080), color=(0,0,0), duration=duration)

    def analyze_script(self, text, search_source="vector"):
        """
        æ–‡æœ¬è½¬åˆ†é•œ
        search_source: 'vector' (ä¼˜å…ˆæœ¬åœ°) | 'pexels' (åªç”¨åœ¨çº¿)
        """
        print(f"ğŸ¤– Calling LLM: {self.llm_model_name}...")
        import concurrent.futures

        # 1. é¢„å¤„ç†ï¼šåˆ†å¥
        text_clean_for_split = re.sub(r'[\(ï¼ˆ].*?[\)ï¼‰]', '', text).strip()
        pre_split_segments = self.smart_split_text(text_clean_for_split, max_chars=30)
        if not pre_split_segments: return []

        total_segments = len(pre_split_segments)
        print(f"ğŸ“ æ€»è®¡ {total_segments} ä¸ªåˆ†é•œï¼Œå‡†å¤‡åˆ†æ...")

        # é…ç½®å¹¶å‘
        BATCH_SIZE = 8
        MAX_WORKERS = 1 if self.llm_provider == 'ollama' else 4 
        final_results = [None] * total_segments

        def process_batch(batch_data):
            batch_index, segment_chunk = batch_data
            chunk_json = json.dumps(segment_chunk, ensure_ascii=False)

            # === [æ ¸å¿ƒä¿®æ”¹] æç¤ºè¯å‡çº§ï¼šå¢åŠ  'fx' (VFX) å­—æ®µ ===
            if search_source == 'vector':
                fx_prompt = """
                **å…·è±¡ä¸»ä½“** (é€‚åˆPexels): å…·ä½“çš„åŠ¨ä½œæˆ–ç‰©ä½“ï¼Œå¦‚ "man running", "clock ticking", "fist hitting table"ã€‚
                """
            else:
                fx_prompt = """
                **æƒ…ç»ªæ°›å›´** (é€‚åˆå‘é‡åº“): æŠ½è±¡çš„æ„Ÿè§‰ï¼Œå¦‚ "anxiety", "loneliness", "oppression", "chaos"ã€‚
                """

            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªè§†é¢‘è„šæœ¬å¯¼æ¼”ã€‚è¯·åˆ†æè¾“å…¥çš„æ–‡æ¡ˆåˆ—è¡¨ã€‚
            
            ã€è¾“å…¥æ•°æ®ã€‘
            {chunk_json}
            
            ã€ä»»åŠ¡ã€‘
            æŒ‰é¡ºåºä¸ºæ¯ä¸€å¥ç”Ÿæˆ JSON å¯¹è±¡ã€‚
            
            ã€å±æ€§è¦æ±‚ã€‘
            1. "v": (visual_tags) è¿”å›ä¸€ä¸ªåŒ…å« 2-3 ä¸ªè‹±æ–‡çŸ­è¯­çš„æ•°ç»„ (Array)ï¼Œå¿…é¡»è¦†ç›–ä»¥ä¸‹ç»´åº¦ä»¥æé«˜åŒ¹é…ç‡ï¼š
               {fx_prompt}
               - ä¾‹å¦‚: ["man sitting alone", "solitude", "dark noir style"]
            2. "k": (keywords) æå– 1-3 ä¸ªå­—çš„ä¸­æ–‡é‡ç‚¹è¯ (ç”¨äºå­—å¹•é«˜äº®)ã€‚
            3. "s": (sfx) éŸ³æ•ˆã€‚å¯é€‰ [Boom, Whoosh, Ding, Keyboard, Glass_Shatter, Silence]ã€‚æ— åˆ™ç•™ç©ºã€‚
            4. "e": (is_emphasis) Booleanï¼Œæ˜¯å¦ä¸ºé‡‘å¥ (true/false)ã€‚
            5. "fx": (visual_effect) è¿é•œæŒ‡ä»¤ã€‚æ ¹æ®å¥å­æƒ…ç»ªé€‰æ‹©ï¼š
               - "Zoom_In_Slow" (é»˜è®¤ï¼Œé€šç”¨)
               - "Zoom_In_Fast" (å¼ºè°ƒã€éœ‡æƒŠ)
               - "Pan_Right" (å™è¿°ã€è¿‡ç¨‹)
               - "Shake" (ç„¦è™‘ã€æ··ä¹±ã€ç—›è‹¦)
               - "Slow_Mo" (å²è¯—ã€æ€»ç»“ã€å”¯ç¾)
            
            ã€è¾“å‡ºæ ¼å¼ã€‘
            çº¯ JSON åˆ—è¡¨ï¼Œæ—  Markdownï¼š
            [
              {{"v": ["city", "night"], "k": "å¤œæ™¯", "s": "whoosh", "e": false, "fx": "Pan_Right"}},
              {{"v": ["fist", "punch"], "k": "åå‡»", "s": "boom", "e": true, "fx": "Zoom_In_Fast"}}
            ]
            """
            
            try:
                response = self._call_llm(prompt)
                # æ¸…æ´— JSON
                clean_content = re.sub(r'```json\s*', '', response)
                clean_content = re.sub(r'```', '', clean_content).strip()
                s = clean_content.find('[')
                e = clean_content.rfind(']') + 1
                if s != -1 and e != -1:
                    clean_content = clean_content[s:e]
                return batch_index, json.loads(clean_content)
            except Exception as e:
                print(f"âš ï¸ Batch {batch_index} Error: {e}")
                return batch_index, []

        # æ‰§è¡Œ LLM åˆ†æ
        batches = []
        for i in range(0, total_segments, BATCH_SIZE):
            chunk = pre_split_segments[i : i + BATCH_SIZE]
            batches.append((i, chunk))

        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            future_to_batch = {executor.submit(process_batch, b): b for b in batches}
            for future in concurrent.futures.as_completed(future_to_batch):
                start_idx, result_list = future.result()
                chunk_len = len(batches[start_idx // BATCH_SIZE][1])
                
                for offset in range(chunk_len):
                    abs_index = start_idx + offset
                    original_text = pre_split_segments[abs_index]
                    
                    # é»˜è®¤æ•°æ®
                    scene_data = {
                        "text": original_text,
                        "visual_tags": ["abstract"],
                        "keywords": "",
                        "sfx_search": "",
                        "is_emphasis": False,
                        "visual_effect": {"camera": "Zoom_In_Slow", "filter": "None"} # é»˜è®¤ç‰¹æ•ˆ
                    }
                    
                    if result_list and offset < len(result_list):
                        item = result_list[offset]
                        scene_data["visual_tags"] = item.get("v", ["abstract"])
                        scene_data["keywords"] = item.get("k", "")
                        scene_data["sfx_search"] = item.get("s", "")
                        scene_data["is_emphasis"] = item.get("e", False)
                        
                        # [æ–°å¢] è§£æè¿é•œæŒ‡ä»¤
                        fx_code = item.get("fx", "Zoom_In_Slow")
                        # ç®€å•çš„é€»è¾‘ï¼šå¦‚æœæ˜¯ Shakeï¼Œæ»¤é•œåŠ ä¸ª High_Contrast å¢åŠ æ°›å›´
                        filter_code = "High_Contrast" if fx_code == "Shake" else "None"
                        scene_data["visual_effect"] = {"camera": fx_code, "filter": filter_code}
                    
                    final_results[abs_index] = scene_data

        # 4. åå¤„ç†ï¼šèµ„æºåŒ¹é… (æ ¹æ® search_source å‚æ•°)
        print(f"ğŸ” æ­£åœ¨åŒ¹é…è§†é¢‘ç´ æ (Mode: {search_source})...")
        used_identifiers = set()
        final_scenes = []

        for scene_data in final_results:
            if scene_data is None: continue 
            
            # æ ¼å¼åŒ– keywords
            kw = scene_data.get('keywords')
            if isinstance(kw, list): scene_data['keywords'] = ", ".join([str(k) for k in kw])
            elif kw is None: scene_data['keywords'] = ""
            else: scene_data['keywords'] = str(kw)

            scene_data['voice'] = config.DEFAULT_VOICE
            scene_data['video_info'] = {"type": "smart_search", "tags": []} 
            
            tags = scene_data.get('visual_tags', [])
            if isinstance(tags, str): tags = [tags]
            scene_data['video_info']['tags'] = tags

            match_found = False
            main_tag = tags[0] if tags else "abstract"

            # ================= [æ ¸å¿ƒä¿®æ”¹] æœç´¢åˆ†æ”¯æ§åˆ¶ =================
            
            # --- åˆ†æ”¯ A: ä¼˜å…ˆå‘é‡æœç´¢ (é»˜è®¤) ---
            if search_source == "vector":
                vector_matches = self.search_vector_match(main_tag, top_k=1)
                if vector_matches:
                    best_path = vector_matches[0]
                    scene_data['video_info'] = {
                        "type": "local", 
                        "src": best_path, 
                        "name": os.path.basename(best_path),
                        "tags": tags 
                    }
                    print(f"   âœ… Vector Hit: {main_tag} -> {os.path.basename(best_path)}")
                    match_found = True
            
            # --- åˆ†æ”¯ B: Pexels æœç´¢ (ä½œä¸º fallback æˆ– æŒ‡å®šæ¨¡å¼) ---
            # å¦‚æœæ¨¡å¼æ˜¯ 'pexels'ï¼Œæˆ–è€…æ¨¡å¼æ˜¯ 'vector' ä½†æ²¡æœåˆ°
            if not match_found and (search_source == "pexels" or search_source == "vector"):
                # å¦‚æœæ˜¯ vector æ¨¡å¼æ²¡æœåˆ°ï¼Œæ‰“å°æ—¥å¿—
                if search_source == "vector":
                    print(f"   ğŸŒ Vector Miss, trying Pexels: {main_tag}")
                
                online_info = self.search_online_videos(main_tag)
                if isinstance(online_info, list) and online_info:
                    selected_vid = None
                    for vid in online_info:
                        if str(vid['id']) not in used_identifiers:
                            selected_vid = vid
                            used_identifiers.add(str(vid['id']))
                            break
                    if not selected_vid: selected_vid = random.choice(online_info)
                    scene_data['video_info'] = selected_vid
                    match_found = True

            # 3. å…œåº•
            if not match_found:
                scene_data['video_info'] = {"type": "random", "tags": tags}

            final_scenes.append(scene_data)

        return final_scenes

    # --- æ¸²æŸ“æ ¸å¿ƒ ---
    async def render_project(self, params, output_file, log_callback=None):
        # å…¨å±€å»é‡é›†åˆï¼Œè´¯ç©¿æ•´ä¸ªè§†é¢‘
        global_used_paths = set() 
        loop = asyncio.get_running_loop()
        
        async def log(msg):
            print(msg)
            if log_callback: await log_callback(msg)

        try:
            await log("ğŸ¬ åˆå§‹åŒ–æ¸²æŸ“å¼•æ“...")
            scene_data = params['scenes']
            bgm_file = params.get('bgm_file', '')
            bgm_vol = float(params.get('bgm_volume', 0.1))
            global_padding = float(params.get('audio_padding', 0)) 
            tts_rate = params.get('tts_rate', config.DEFAULT_TTS_RATE)
            sub_style = params.get('subtitle_style', {})
            search_source = params.get('search_source', 'vector')

            json_file = output_file.replace('.mp4', '.json')
            try:
                with open(json_file, 'w', encoding='utf-8') as f:
                    json.dump(params, f, ensure_ascii=False, indent=2)
                await log(f"ğŸ’¾ é¡¹ç›®æ–‡ä»¶å·²ä¿å­˜")
            except: pass

            norm_style = sub_style.get('normal', {})
            emp_style = sub_style.get('emphasis', {})
            ass_color_normal = self.hex_to_ass_color(norm_style.get('color', '#FFFFFF'))
            ass_color_highlight = self.hex_to_ass_color(emp_style.get('color', '#FF0000'))

            for f in glob.glob(os.path.join(self.TEMP_DIR, "scene_*.mp4")): os.remove(f)
            
            scene_files = []
            subtitles_events = []
            current_time = 0.0
            total_scenes = len(scene_data)

            custom_logger = WebSocketLogger(log_callback, loop)

            for idx, scene in enumerate(scene_data):
                text = scene['text']
                voice = scene.get('voice', config.DEFAULT_VOICE)
                sfx = scene.get('sfx_search', '')
                is_emphasis = scene.get('is_emphasis', False)
                keywords = scene.get('keywords', '').strip()
                scene_padding = float(scene.get('audio_padding', global_padding))
                video_info = scene.get('video_info', {})

                await log(f"ğŸ”¨ å¤„ç†åˆ†é•œ {idx+1}/{total_scenes}...")
                
                raw_text_clean = re.sub(r'[\(ï¼ˆ].*?[\)ï¼‰]', '', text).strip()
                if not raw_text_clean: continue

                sub_chunks = self.smart_split_text(raw_text_clean, max_chars=15)
                scene_audio_clips = []
                scene_total_duration = 0.0
                
                for sub_idx, chunk in enumerate(sub_chunks):
                    tts_text = chunk.strip()
                    
                    if not tts_text or not re.search(r'[\u4e00-\u9fa5a-zA-Z0-9]', tts_text):
                        continue

                    tpath = os.path.join(self.TEMP_DIR, f"tts_{idx}_{sub_idx}.mp3")
                    
                    tts_success = False
                    for _ in range(3):
                        try:
                            await edge_tts.Communicate(tts_text, voice, rate=tts_rate).save(tpath)
                            if os.path.exists(tpath) and os.path.getsize(tpath) > 1024:
                                tts_success = True; break
                        except: await asyncio.sleep(1)
                    
                    if not tts_success:
                        ac = AudioArrayClip(np.zeros((44100, 2)), fps=44100).set_duration(0.1)
                        await log(f"âš ï¸ TTSå¤±è´¥ï¼Œè·³è¿‡: {tts_text[:5]}")
                    else:
                        try:
                            ac = AudioFileClip(tpath).volumex(1.5)
                        except:
                            ac = AudioArrayClip(np.zeros((44100, 2)), fps=44100).set_duration(0.1)

                    chunk_dur = ac.duration + scene_padding
                    scene_audio_clips.append(ac.set_start(scene_total_duration))
                    
                    start_s = self.format_ass_time(current_time + scene_total_duration)
                    end_s = self.format_ass_time(current_time + scene_total_duration + chunk_dur)
                    
                    disp = self.clean_for_subtitle(chunk)
                    
                    if disp:
                        if is_emphasis:
                            # 1. éœ¸å±æ¨¡å¼ä¼˜åŒ–ï¼šä¸å†æš´åŠ›åˆ‡æ–­ï¼Œè€Œæ˜¯æ™ºèƒ½æ¢è¡Œ
                            content = disp
                            
                            # ç­–ç•¥ï¼šå¦‚æœæœ‰æ ‡ç‚¹ï¼ˆé¡¿å·ã€é€—å·ï¼‰ï¼Œä¼˜å…ˆåœ¨æ ‡ç‚¹åæ¢è¡Œ
                            if "ã€" in content:
                                content = content.replace("ã€", "ã€\\N")
                            elif "ï¼Œ" in content:
                                content = content.replace("ï¼Œ", "ï¼Œ\\N")
                            elif len(content) > 12: 
                                # åªæœ‰çœŸçš„éå¸¸é•¿ä¸”æ²¡æ ‡ç‚¹æ—¶ï¼Œæ‰åœ¨ä¸­é—´æ¢è¡Œ
                                mid = len(content) // 2
                                content = content[:mid] + "\\N" + content[mid:]
                                
                            # ç§»é™¤æœ«å°¾å¯èƒ½å¤šä½™çš„æ¢è¡Œç¬¦
                            if content.endswith("\\N"): content = content[:-2]

                            ass_l = f"Dialogue: 1,{start_s},{end_s},Emphasis,,0,0,0,,{{\\fad(50,0)}}{content}"
                            subtitles_events.append(ass_l)
                        else:
                            # 2. æ™®é€šæ¨¡å¼ (åŒè½¨)
                            ass_bottom = f"Dialogue: 1,{start_s},{end_s},Normal,,0,0,0,,{{\\fad(80,80)}}{disp}"
                            subtitles_events.append(ass_bottom)
                            
                            # if keywords:
                            #     kws = [k.strip() for k in re.split(r'[,ï¼Œ]', keywords) if k.strip()]
                            #     if kws:
                            #         kw_str = "\\N".join(kws) if len(kws)>1 or sum(len(k) for k in kws)>8 else "  ".join(kws)
                            #         ass_center = f"Dialogue: 1,{start_s},{end_s},Emphasis,,0,0,0,,{{\\fad(50,50)}}{kw_str}"
                            #         subtitles_events.append(ass_center)
                    
                    scene_total_duration += chunk_dur

                if not scene_audio_clips:
                    await log(f"âš ï¸ è·³è¿‡æ— æ•ˆåˆ†é•œ {idx+1}")
                    continue

                combined_audio = CompositeAudioClip(scene_audio_clips).set_duration(scene_total_duration)
                
                final_audio = [combined_audio]
                
                if sfx:
                    sp = self.download_sfx_manual(sfx)
                    if sp:
                         sp_path = os.path.join(self.ASSETS_DIR, "sfx", sp)
                         try: 
                             af = AudioFileClip(sp_path).volumex(0.6).set_start(0)
                             final_audio.append(af)
                             await log(f"   ğŸ”Š æ·»åŠ éŸ³æ•ˆ: {os.path.basename(sp)}")
                         except: pass

                

                # åˆå§‹åŒ– vc (Video Clip)
                vc = None

                # --- åˆ†æ”¯ A: å‘é‡åº“ + æ™ºèƒ½æ··å‰ª + åŠ¨æ•ˆ (Vector Mode) ---
                if search_source == 'vector':
                    effect_config = scene.get('visual_effect', {})
                    candidate_pool = []
                    
                    # [å…³é”®ä¿®æ”¹] Step 1: æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒ‡å®šçš„æœ¬åœ°è§†é¢‘ (ç”¨æˆ·å·²é€‰ æˆ– é¢„è§ˆå·²é”å®š)
                    v_info = scene.get('video_info', {})
                    specific_path = None
                    
                    if isinstance(v_info, dict) and v_info.get('type') == 'local':
                        # ä¼˜å…ˆå– download_url (åç«¯å­˜å‚¨çš„ç»å¯¹è·¯å¾„)ï¼Œå…¶æ¬¡å– src
                        p = v_info.get('download_url') or v_info.get('src')
                        if p and os.path.exists(p):
                            specific_path = p
                    
                    if specific_path:
                        print(f"   ğŸ”’ [Locked] Using specific clip: {os.path.basename(specific_path)}")
                        # å¦‚æœé”å®šäº†è§†é¢‘ï¼Œå€™é€‰æ± é‡Œåªæ”¾è¿™ä¸€æ¡
                        # get_dynamic_visuals_smart ä¼šä¼˜å…ˆç”¨å®ƒï¼Œå¦‚æœæ—¶é•¿ä¸å¤Ÿï¼Œä¼šæ ¹æ®é€»è¾‘å¾ªç¯å®ƒæˆ–è€…éšæœºå¡«å……
                        candidate_pool = [specific_path]
                        
                    else:
                        # [åŸé€»è¾‘] Step 2: æ²¡æœ‰æŒ‡å®šè§†é¢‘ï¼Œæ‰è¿›è¡Œå…³é”®è¯æœç´¢
                        raw_queries = scene.get('visual_tags', [])
                        if isinstance(raw_queries, str): raw_queries = [raw_queries]
                        if not raw_queries:
                            kw = scene.get('keywords', '')
                            if kw: raw_queries = [kw]
                        
                        if raw_queries:
                            print(f"   ğŸ” [Auto] Searching: {raw_queries}")
                            for q in raw_queries:
                                matches = self.search_vector_match(q, top_k=3, exclude_set=global_used_paths)
                                candidate_pool.extend(matches)

                    # Step 3: è°ƒç”¨æ™ºèƒ½å¡«å……
                    # æ³¨æ„ï¼šå¦‚æœ candidate_pool æ˜¯ç”¨æˆ·é”å®šçš„ 1 ä¸ªè§†é¢‘ï¼ŒSmart Fill ä¼šä¼˜å…ˆä½¿ç”¨å®ƒã€‚
                    # å¦‚æœè¿™ 1 ä¸ªè§†é¢‘ä¸å¤Ÿé•¿ï¼ŒSmart Fill ç›®å‰çš„é€»è¾‘æ˜¯ä¼šå»éšæœºåº“é‡Œæ‹¿è§†é¢‘è¡¥ã€‚
                    # å¦‚æœä½ å¸Œæœ›â€œé”å®šäº†å°±åªå¾ªç¯è¿™ä¸€ä¸ªï¼Œä¸è¦è¡¥å…¶ä»–çš„â€ï¼Œéœ€è¦æ”¹ Smart Fillï¼Œä½†ç›®å‰é€»è¾‘ç¬¦åˆâ€œæ··å‰ªâ€è°ƒæ€§ã€‚
                    vc = self.get_dynamic_visuals_smart(
                        candidate_pool, 
                        scene_total_duration, 
                        global_used_paths,
                        effect_config=effect_config
                    )

                # --- åˆ†æ”¯ B: Pexels / ä¼ ç»Ÿæ¨¡å¼ (Legacy Mode) ---
                else:
                    print(f"   ğŸŒ [Pexels Mode] Fetching video...")
                    # ä¼ ç»Ÿçš„ä¸‹è½½é€»è¾‘ (scene['video_info'] é‡Œé€šå¸¸æ˜¯ Pexels URL)
                    vc = self.get_video_clip_safe(video_info, scene_total_duration, log)
                    
                    if vc.duration > scene_total_duration:
                        vc = vc.subclip(0, scene_total_duration)
                    elif vc.duration < scene_total_duration:
                        vc = vc.loop(duration=scene_total_duration)
                    
                    vc = vc.set_duration(scene_total_duration)
                    

                
                # --- [æ ¸å¿ƒä¿®å¤ï¼šç‰©ç†æˆªå–è§†é¢‘] ---
                # 1. ç¡®ä¿è§†é¢‘è¢«ç‰©ç†æˆªæ–­åˆ°æŒ‡å®šæ—¶é•¿
                # get_video_clip_safe å†…éƒ¨è™½ç„¶æœ‰ subclipï¼Œä½†ä¸ºäº†ä¿é™©ï¼Œè¿™é‡Œå†æ¬¡å¼ºåˆ¶æ‰§è¡Œ
                # å¦‚æœè§†é¢‘æ¯”éŸ³é¢‘é•¿ï¼Œå¼ºåˆ¶æˆªå–å‰ scene_total_duration ç§’
                if vc.duration > scene_total_duration:
                    # éšæœºæ‰¾ä¸€ä¸ªèµ·ç‚¹ (æˆ–è€…ä»å¤´å¼€å§‹)
                    # æ³¨æ„ï¼šget_video_clip_safe å·²ç»åšè¿‡éšæœºäº†ï¼Œè¿™é‡Œç›´æ¥æˆªå– 0 åˆ° end å³å¯
                    vc = vc.subclip(0, scene_total_duration)
                elif vc.duration < scene_total_duration:
                    # å¦‚æœè§†é¢‘ä¸å¤Ÿé•¿ï¼Œå¾ªç¯æ’­æ”¾
                    vc = vc.loop(duration=scene_total_duration)
                
                # 2. å†æ¬¡æ˜¾å¼è®¾ç½® duration (åŒé‡ä¿é™©)
                vc = vc.set_duration(scene_total_duration)
                
                # 3. ç§»é™¤åŸå£° (é˜²æ­¢ç´ æè‡ªå¸¦å£°éŸ³å¹²æ‰°)
                vc = vc.without_audio()
                
                # 4. åˆæˆéŸ³é¢‘
                final_audio_clip = CompositeAudioClip(final_audio).set_duration(scene_total_duration)
                vc = vc.set_audio(final_audio_clip)
                
                # 5. å†™å…¥æ–‡ä»¶
                scene_out = os.path.join(self.TEMP_DIR, f"scene_{idx}.mov")
                
                def write_segment():
                    vc.write_videofile(
                        scene_out, 
                        fps=30, 
                        preset="ultrafast", 
                        logger=custom_logger, 
                        codec="libx264", 
                        audio_codec="pcm_s16le", 
                        temp_audiofile=f"{self.TEMP_DIR}/temp_{idx}.wav", 
                        remove_temp=True
                    )
                
                await asyncio.to_thread(write_segment)
                
                vc.close()
                combined_audio.close()
                scene_files.append(scene_out)
                current_time += scene_total_duration

            if not scene_files: return False
            await log("ğŸ”— ç¼åˆè§†é¢‘...")
            list_path = os.path.join(self.TEMP_DIR, "concat.txt")
            with open(list_path, "w", encoding="utf-8") as f:
                for p in scene_files:
                    safe_p = os.path.abspath(p).replace("\\", "/")
                    f.write(f"file '{safe_p}'\n")

            temp_concat = os.path.join(self.TEMP_DIR, "temp_concat.mov")
            
            def format_p(path): return os.path.abspath(path).replace("\\", "/")
            safe_concat = format_p(temp_concat)
            safe_list = format_p(list_path)

            await self.run_ffmpeg_async(["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", safe_list, "-c", "copy", safe_concat], log_callback, loop)
            
            await log("ğŸµ æ··åˆBGM...")
            final_clip = VideoFileClip(temp_concat)
            if bgm_file:
                bp = os.path.join(self.ASSETS_DIR, "music", bgm_file)
                if os.path.exists(bp):
                    try:
                        bgm = AudioFileClip(bp).volumex(bgm_vol)
                        from moviepy.audio.fx.all import audio_loop
                        bgm = audio_loop(bgm, duration=final_clip.duration)
                        final_clip = final_clip.set_audio(CompositeAudioClip([final_clip.audio, bgm]) if final_clip.audio else bgm)
                    except: pass
            
            temp_video_bgm = os.path.join(self.TEMP_DIR, "temp_with_bgm.mov")
            
            def write_bgm():
                final_clip.write_videofile(temp_video_bgm, fps=30, codec="libx264", audio_codec="pcm_s16le", temp_audiofile="temp_final.wav", remove_temp=True, logger=custom_logger)
            
            await asyncio.to_thread(write_bgm)
            final_clip.close()

            await log("ğŸ“ å‹åˆ¶å­—å¹•ä¸æœ€ç»ˆè¾“å‡º...")
            ass_str = self.generate_ass_header(sub_style)
            for l in subtitles_events: ass_str += l + "\n"
            
            ass_p = os.path.abspath(os.path.join(self.TEMP_DIR, "s.ass"))
            with open(ass_p, "w", encoding="utf-8") as f: f.write(ass_str)
            
            fdir = os.path.abspath(os.path.join(self.ASSETS_DIR, "fonts"))
            font_p = os.path.join(fdir, "font.ttf")
            
            safe_ass = format_p(ass_p)
            safe_fdir = format_p(fdir)
            safe_in = format_p(temp_video_bgm)
            safe_out = format_p(output_file)
            
            vf = f"ass='{safe_ass}':fontsdir='{safe_fdir}'" if os.path.exists(font_p) else f"ass='{safe_ass}'"
            
            await self.run_ffmpeg_async([
                "ffmpeg", "-y", 
                "-i", safe_in, 
                "-vf", vf, 
                "-c:v", "libx264", "-preset", "fast", "-crf", "23", 
                "-c:a", "aac", "-b:a", "192k", 
                safe_out
            ], log_callback, loop)
            
            os.remove(temp_video_bgm); os.remove(temp_concat); os.remove(list_path); os.remove(ass_p)
            shutil.rmtree(self.TEMP_DIR); os.makedirs(self.TEMP_DIR, exist_ok=True)
            
            final_filename = os.path.basename(output_file)
            final_url = f"/outputs/{final_filename}"
            await log(f"âœ… å¤„ç†å®Œæˆ@@@{final_url}")
            return True

        except Exception as e:
            await log(f"âŒ Error: {traceback.format_exc()}")
            return False